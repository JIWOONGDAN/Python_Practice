{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result == 6.000000000012662\n"
     ]
    }
   ],
   "source": [
    "# 수치미분 1차 버전 - NUMERICAL DERIVATIIVE\n",
    "\n",
    "def my_func1(x):\n",
    "    \n",
    "    return x**2\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "\n",
    "    delta_x = 1e-4\n",
    "    \n",
    "    return (f(x + delta_x) - f(x - delta_x)) / (2 * delta_x)\n",
    "\n",
    "result = numerical_derivative(my_func1, 3)\n",
    "\n",
    "print(\"result ==\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result == 66.50150507518049\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def my_func2(x):\n",
    "    \n",
    "    return 3 * x * np.exp(x)\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    \n",
    "    delta_x = 1e-4\n",
    "    \n",
    "    return (f(x + delta_x) - f(x - delta_x)) / (2 * delta_x)\n",
    "\n",
    "result = numerical_derivative(my_func2, 2)\n",
    "\n",
    "print(\"result ==\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3*exp(2) + 3*2*exp(2) == 66.50150489037586\n"
     ]
    }
   ],
   "source": [
    "print(\"3*exp(2) + 3*2*exp(2) ==\", 3*np.exp(2) + 3*2*np.exp(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치미분 최종 버전- NUMERICAL DERIVATIIVE\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    \n",
    "    delta_x = 1e-4\n",
    "    \n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    \n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    print(\"debug 1. initial input variable =\", x)\n",
    "    print(\"debug 2. initial grad =\", grad)\n",
    "    print(\"========================================\")\n",
    "    \n",
    "    it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        print(\"debug 3. idx = \", idx, \", x[idx] =\", x[idx])\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val -delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2 * delta_x)\n",
    "        \n",
    "        print(\"debug 4. grad[idx] = \", grad[idx])\n",
    "        print(\"debug 5. grad = \", grad)\n",
    "        print(\"=====================================\")\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug 1. initial input variable = [3.]\n",
      "debug 2. initial grad = [0.]\n",
      "========================================\n",
      "debug 3. idx =  (0,) , x[idx] = 3.0\n",
      "debug 4. grad[idx] =  6.000000000012662\n",
      "debug 5. grad =  [6.]\n",
      "=====================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#입력변수 1 개인함수 f(X) = x**2\n",
    "\n",
    "def func1(input_obj):\n",
    "    \n",
    "    x = input_obj[0]\n",
    "    \n",
    "    return x**2\n",
    "\n",
    "numerical_derivative(func1, np.array([3.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug 1. initial input variable = [1. 2.]\n",
      "debug 2. initial grad = [0. 0.]\n",
      "========================================\n",
      "debug 3. idx =  (0,) , x[idx] = 1.0\n",
      "debug 4. grad[idx] =  7.999999999990237\n",
      "debug 5. grad =  [8. 0.]\n",
      "=====================================\n",
      "debug 3. idx =  (1,) , x[idx] = 2.0\n",
      "debug 4. grad[idx] =  15.000000010019221\n",
      "debug 5. grad =  [ 8.         15.00000001]\n",
      "=====================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 8.        , 15.00000001])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func2(input_obj):\n",
    "    \n",
    "    x = input_obj[0]\n",
    "    y = input_obj[1]\n",
    "    \n",
    "    return (2*x + 3*x*y + y**3)\n",
    "\n",
    "input = np.array([1.0, 2.0])\n",
    "\n",
    "numerical_derivative(func2, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug 1. initial input variable = [[1. 2.]\n",
      " [3. 4.]]\n",
      "debug 2. initial grad = [[0. 0.]\n",
      " [0. 0.]]\n",
      "========================================\n",
      "debug 3. idx =  (0, 0) , x[idx] = 1.0\n",
      "debug 4. grad[idx] =  5.000000000023874\n",
      "debug 5. grad =  [[5. 0.]\n",
      " [0. 0.]]\n",
      "=====================================\n",
      "debug 3. idx =  (0, 1) , x[idx] = 2.0\n",
      "debug 4. grad[idx] =  13.00000000000523\n",
      "debug 5. grad =  [[ 5. 13.]\n",
      " [ 0.  0.]]\n",
      "=====================================\n",
      "debug 3. idx =  (1, 0) , x[idx] = 3.0\n",
      "debug 4. grad[idx] =  32.00000000006753\n",
      "debug 5. grad =  [[ 5. 13.]\n",
      " [32.  0.]]\n",
      "=====================================\n",
      "debug 3. idx =  (1, 1) , x[idx] = 4.0\n",
      "debug 4. grad[idx] =  15.000000000000568\n",
      "debug 5. grad =  [[ 5. 13.]\n",
      " [32. 15.]]\n",
      "=====================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5., 13.],\n",
       "       [32., 15.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func3(input_obj):\n",
    "    \n",
    "    w = input_obj[0, 0]\n",
    "    x = input_obj[0, 1]\n",
    "    y = input_obj[1, 0]\n",
    "    z = input_obj[1, 1]\n",
    "    \n",
    "    return (w*x + x*y*z + 3*w + z*(y**2))\n",
    "\n",
    "input = np.array([[1.0, 2.0],[3.0, 4.0]])\n",
    "\n",
    "numerical_derivative(func3, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.59207904]] W.shape =  (1, 1) b =  [0.41156886] b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "#Simple regression = exampple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([1, 2, 3, 4, 5]).reshape(5, 1) #입력 예제\n",
    "t_data = np.array([2, 3, 4, 5, 6]).reshape(5, 1) #결과 예제(이미 아는 값)\n",
    "\n",
    "W = np.random.rand(1, 1)\n",
    "b = np.random.rand(1)\n",
    "print(\"W = \", W, \"W.shape = \", W.shape, \"b = \", b, \"b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, t):\n",
    "    y = np.dot(x, W) + b\n",
    "    \n",
    "    return (np.sum((t - y)**2))/(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital error value =  16.42023600063939 Initial W =  [[0.59207904]] \n",
      " , b =  [0.41156886]\n",
      "step =  0 error value =  9.916651714976549 W =  [[0.71712752]] , b =  [0.44030984]\n",
      "step =  400 error value =  0.0020125045628876575 W =  [[1.03291978]] , b =  [0.88117823]\n",
      "step =  800 error value =  0.0001284096889845644 W =  [[1.00831548]] , b =  [0.96998582]\n",
      "step =  1200 error value =  8.193297311808918e-06 W =  [[1.00210048]] , b =  [0.99241847]\n",
      "step =  1600 error value =  5.227808070449919e-07 W =  [[1.00053058]] , b =  [0.99808492]\n",
      "step =  2000 error value =  3.335650615549492e-08 W =  [[1.00013402]] , b =  [0.99951625]\n",
      "step =  2400 error value =  2.1283422953985366e-09 W =  [[1.00003385]] , b =  [0.99987781]\n",
      "step =  2800 error value =  1.358008211679122e-10 W =  [[1.00000855]] , b =  [0.99996913]\n",
      "step =  3200 error value =  8.66489524006005e-12 W =  [[1.00000216]] , b =  [0.9999922]\n",
      "step =  3600 error value =  5.528715415895237e-13 W =  [[1.00000055]] , b =  [0.99999803]\n",
      "step =  4000 error value =  3.527647257672326e-14 W =  [[1.00000014]] , b =  [0.9999995]\n",
      "step =  4400 error value =  2.250847501654558e-15 W =  [[1.00000003]] , b =  [0.99999987]\n",
      "step =  4800 error value =  1.4361738118671086e-16 W =  [[1.00000001]] , b =  [0.99999997]\n",
      "step =  5200 error value =  9.163641411136979e-18 W =  [[1.]] , b =  [0.99999999]\n",
      "step =  5600 error value =  5.846958667432534e-19 W =  [[1.]] , b =  [1.]\n",
      "step =  6000 error value =  3.7306882186846656e-20 W =  [[1.]] , b =  [1.]\n",
      "step =  6400 error value =  2.3805356495367823e-21 W =  [[1.]] , b =  [1.]\n",
      "step =  6800 error value =  1.5188573923905783e-22 W =  [[1.]] , b =  [1.]\n",
      "step =  7200 error value =  9.687668824350328e-24 W =  [[1.]] , b =  [1.]\n",
      "step =  7600 error value =  6.150985530710248e-25 W =  [[1.]] , b =  [1.]\n",
      "step =  8000 error value =  3.924607655377822e-26 W =  [[1.]] , b =  [1.]\n"
     ]
    }
   ],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad\n",
    "\n",
    "def error_val(x, t):\n",
    "\n",
    "    y = np.dot(x, W) + b\n",
    "    \n",
    "    return (np.sum(t - y)**2) / (len(x))\n",
    "\n",
    "def predict(x, t):\n",
    "\n",
    "    y = np.dot(x, W) + b\n",
    "    \n",
    "    return y\n",
    "\n",
    "learning_rate = 1e-2 \n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Inital error value = \", error_val(x_data, t_data), \"Initial W = \", W, \"\\n\", \", b = \", b)\n",
    "\n",
    "for step in range(8001):\n",
    "    \n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape =  (10, 1) t_data.shape =  (10, 1)\n"
     ]
    }
   ],
   "source": [
    "#Simple logistic regression (classification) - example\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20]).reshape(10, 1)\n",
    "t_data = np.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1]).reshape(10, 1)\n",
    "\n",
    "print(\"x_data.shape = \", x_data.shape, \"t_data.shape = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.16092897]] W.shape =  (1, 1) b =  [0.29525095] b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(1, 1)\n",
    "b = np.random.rand(1)\n",
    "print(\"W = \", W, \"W.shape = \", W.shape, \"b = \", b, \"b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def loss_func(x, t):\n",
    "    \n",
    "    delta = 1e-7\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    return -np.sum(t*np.log(y + delta) + (1- t)*np.log((1 - y) + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_val(x, t):\n",
    "    delta = 1e-7\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    return -np.sum(t*np.log(y + delta) + (1 - t)*np.log((1 - y) + delta))\n",
    "\n",
    "def predict(x):\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    if y >= 0.5:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "        \n",
    "    return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital error value =  0.010439801888784113 Initial W =  \n",
      " , b =  [-68.24506103]\n",
      "step =  0 error_val =  0.010439795506695654 W =  [[5.25555382]] b =  [-68.24506901]\n",
      "step =  10000 error_val =  0.010376380466423245 W =  [[5.26165344]] b =  [-68.32447257]\n",
      "step =  20000 error_val =  0.01031372930945598 W =  [[5.26772427]] b =  [-68.40339584]\n",
      "step =  30000 error_val =  0.01025182829004252 W =  [[5.27375865]] b =  [-68.48184518]\n",
      "step =  40000 error_val =  0.010190664036856095 W =  [[5.27975701]] b =  [-68.55982624]\n",
      "step =  50000 error_val =  0.010130223494128367 W =  [[5.28571977]] b =  [-68.63734456]\n",
      "step =  60000 error_val =  0.010070493912408354 W =  [[5.29164736]] b =  [-68.71440558]\n",
      "step =  70000 error_val =  0.010011462839627358 W =  [[5.29754019]] b =  [-68.79101466]\n",
      "step =  80000 error_val =  0.009953118112499453 W =  [[5.30339866]] b =  [-68.86717706]\n",
      "step =  90000 error_val =  0.009895447848195071 W =  [[5.30922317]] b =  [-68.94289794]\n",
      "step =  100000 error_val =  0.00983844043631967 W =  [[5.31501411]] b =  [-69.01818238]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "f = lambda x: loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Inital error value = \", error_val(x_data, t_data), \"Initial W = \", \"\\n\", \", b = \", b)\n",
    "\n",
    "for step in range(100001):\n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 10000 == 0):\n",
    "        print(\"step = \", step, \"error_val = \", error_val(x_data, t_data), \"W = \", W, \"b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.92540926e-24]] 0\n"
     ]
    }
   ],
   "source": [
    "(real_val, logical_val) = predict(3)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] 1\n"
     ]
    }
   ],
   "source": [
    "(real_val, logical_val) = predict(17)\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogicGate class - AND, OR, NADN, XOR 검증\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#external function\n",
    "def sigmoid(x):\n",
    "    \n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogicGate Class\n",
    "\n",
    "class LogicGate:\n",
    "    \n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "    \n",
    "        self.name = gate_name\n",
    "    \n",
    "        self.__xdata = xdata.reshape(4, 2)\n",
    "        self.__tdata = tdata.reshape(4, 1)\n",
    "    \n",
    "        self.__W = np.random.rand(2, 1)\n",
    "        self.__b = np.random.rand(1)\n",
    "    \n",
    "        self.__learning_rate = 1e-2\n",
    "    \n",
    "    def __loss_func(self):\n",
    "        \n",
    "        delta = 1e-7\n",
    "        \n",
    "        z = np.dot(self.__xdata, self.__W) + self.__b\n",
    "        y = sigmoid(z)\n",
    "        \n",
    "        return - np.sum(self.__tdata*np.log(y + delta) + (1 - self.__tdata)*np.log((1 - y) + delta))\n",
    "    \n",
    "    \n",
    "    def error_val(self):\n",
    "        \n",
    "        delta = 1e-7\n",
    "        \n",
    "        z = np.dot(self.__xdata, self.__W) + self.__b\n",
    "        y = sigmoid(z)\n",
    "        \n",
    "        return - np.sum(self.__tdata*np.log(y + delta) + (1 - self.__tdata)*np.log((1 - y) + delta))  \n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        f = lambda x: self.__loss_func()\n",
    "        \n",
    "        print(\"Initial error value = \", self.error_val())\n",
    "        \n",
    "        for step in range(10001):\n",
    "            self.__W -= self.__learning_rate * numerical_derivative(f, self.__W)\n",
    "            self.__b -= self.__learning_rate * numerical_derivative(f, self.__b)\n",
    "            \n",
    "            if (step % 400 == 0):\n",
    "                print(\"step = \", step, \"error value = \", self.error_val())\n",
    "                \n",
    "    def predict(self, input_data):\n",
    "        \n",
    "        z = np.dot(input_data, self.__W) + self.__b\n",
    "        y = sigmoid(z)\n",
    "        \n",
    "        if y > 0.5:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "            \n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  4.72275018666052\n",
      "step =  0 error value =  4.6611236897747865\n",
      "step =  400 error value =  1.4673584398986437\n",
      "step =  800 error value =  1.1063053741105726\n",
      "step =  1200 error value =  0.8958586960504658\n",
      "step =  1600 error value =  0.7549398858747739\n",
      "step =  2000 error value =  0.6527869891690069\n",
      "step =  2400 error value =  0.574898105427028\n",
      "step =  2800 error value =  0.5133859746448217\n",
      "step =  3200 error value =  0.46352311762437703\n",
      "step =  3600 error value =  0.42227345978610364\n",
      "step =  4000 error value =  0.3875848184081989\n",
      "step =  4400 error value =  0.35801433452105424\n",
      "step =  4800 error value =  0.3325152889901343\n",
      "step =  5200 error value =  0.310308670029092\n",
      "step =  5600 error value =  0.29080218525515505\n",
      "step =  6000 error value =  0.2735372467301347\n",
      "step =  6400 error value =  0.2581531687464701\n",
      "step =  6800 error value =  0.2443623428721588\n",
      "step =  7200 error value =  0.2319326294117085\n",
      "step =  7600 error value =  0.22067461837099112\n",
      "step =  8000 error value =  0.2104322517284379\n",
      "step =  8400 error value =  0.20107581270498137\n",
      "step =  8800 error value =  0.1924966116206897\n",
      "step =  9200 error value =  0.18460290721536823\n",
      "step =  9600 error value =  0.17731674056498198\n",
      "step =  10000 error value =  0.1705714518758898\n"
     ]
    }
   ],
   "source": [
    "#usage (data feedingm, AND Gate 검증)\n",
    "\n",
    "xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "tdata = np.array([0, 0, 0, 1])\n",
    "\n",
    "AND_obj = LogicGate(\"AND_GATE\", xdata, tdata)\n",
    "\n",
    "AND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND_GATE \n",
      "\n",
      "[0 0]  =  0 \n",
      "\n",
      "[0 1]  =  0 \n",
      "\n",
      "[1 0]  =  0 \n",
      "\n",
      "[1 1]  =  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(AND_obj.name, \"\\n\")\n",
    "\n",
    "test_data = np.array([[0, 0],[0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = AND_obj.predict(input_data)\n",
    "    print(input_data, \" = \", logical_val, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  1.8100164085363257\n",
      "step =  0 error value =  1.8048713899845508\n",
      "step =  400 error value =  1.089601324497761\n",
      "step =  800 error value =  0.7920912990141495\n",
      "step =  1200 error value =  0.6167198162183908\n",
      "step =  1600 error value =  0.5020789587558926\n",
      "step =  2000 error value =  0.4217428644110071\n",
      "step =  2400 error value =  0.36258455382034593\n",
      "step =  2800 error value =  0.3173631799478168\n",
      "step =  3200 error value =  0.28176845086656316\n",
      "step =  3600 error value =  0.2530817317522756\n",
      "step =  4000 error value =  0.22950810415233283\n",
      "step =  4400 error value =  0.20981757928354589\n",
      "step =  4800 error value =  0.19314075487555382\n",
      "step =  5200 error value =  0.17884674169554016\n",
      "step =  5600 error value =  0.16646727062477232\n",
      "step =  6000 error value =  0.1556478819446211\n",
      "step =  6400 error value =  0.14611559959017967\n",
      "step =  6800 error value =  0.13765696809457928\n",
      "step =  7200 error value =  0.13010278968087235\n",
      "step =  7600 error value =  0.12331730251843363\n",
      "step =  8000 error value =  0.11719036872164844\n",
      "step =  8400 error value =  0.11163174295869219\n",
      "step =  8800 error value =  0.10656680539294733\n",
      "step =  9200 error value =  0.10193334212624668\n",
      "step =  9600 error value =  0.09767908616364152\n",
      "step =  10000 error value =  0.09375981809208682\n"
     ]
    }
   ],
   "source": [
    "#usage (data feedingm, OR Gate 검증)\n",
    "\n",
    "xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "tdata = np.array([0, 1, 1, 1])\n",
    "\n",
    "OR_obj = LogicGate(\"OR_GATE\", xdata, tdata)\n",
    "\n",
    "OR_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR_GATE \n",
      "\n",
      "[0 0]  =  0 \n",
      "\n",
      "[0 1]  =  1 \n",
      "\n",
      "[1 0]  =  1 \n",
      "\n",
      "[1 1]  =  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OR_obj.name, \"\\n\")\n",
    "\n",
    "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = OR_obj.predict(input_data)\n",
    "    print(input_data, \" = \", logical_val, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  2.6947965704250167\n",
      "step =  0 error value =  2.690239490232786\n",
      "step =  400 error value =  1.619510106306274\n",
      "step =  800 error value =  1.1842661468661275\n",
      "step =  1200 error value =  0.944513674037436\n",
      "step =  1600 error value =  0.7887546910480029\n",
      "step =  2000 error value =  0.6778621349759736\n",
      "step =  2400 error value =  0.5943112548838981\n",
      "step =  2800 error value =  0.5288876288894777\n",
      "step =  3200 error value =  0.47619551096992074\n",
      "step =  3600 error value =  0.43282740120597835\n",
      "step =  4000 error value =  0.39650897664798146\n",
      "step =  4400 error value =  0.3656568665868115\n",
      "step =  4800 error value =  0.33913147340572497\n",
      "step =  5200 error value =  0.3160901758511374\n",
      "step =  5600 error value =  0.29589582561900896\n",
      "step =  6000 error value =  0.27805741741318085\n",
      "step =  6400 error value =  0.26219034129536756\n",
      "step =  6800 error value =  0.24798900918383782\n",
      "step =  7200 error value =  0.23520755255965525\n",
      "step =  7600 error value =  0.22364592972956934\n",
      "step =  8000 error value =  0.21313974517017192\n",
      "step =  8400 error value =  0.20355266928750515\n",
      "step =  8800 error value =  0.19477071343889593\n",
      "step =  9200 error value =  0.1866978503562288\n",
      "step =  9600 error value =  0.1792526246434477\n",
      "step =  10000 error value =  0.1723655016017429\n"
     ]
    }
   ],
   "source": [
    "#usage (data feedingm, NAND Gate 검증)\n",
    "\n",
    "xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "tdata = np.array([1, 1, 1, 0])\n",
    "\n",
    "NAND_obj = LogicGate(\"NAND_GATE\", xdata, tdata)\n",
    "\n",
    "NAND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND_GATE \n",
      "\n",
      "[0 0]  =  1 \n",
      "\n",
      "[0 1]  =  1 \n",
      "\n",
      "[1 0]  =  1 \n",
      "\n",
      "[1 1]  =  0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(NAND_obj.name, \"\\n\")\n",
    "\n",
    "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = NAND_obj.predict(input_data)\n",
    "    print(input_data, \" = \", logical_val, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  3.197073561680144\n",
      "step =  0 error value =  3.187186678762868\n",
      "step =  400 error value =  2.789006067440339\n",
      "step =  800 error value =  2.777110725701483\n",
      "step =  1200 error value =  2.7738508219171587\n",
      "step =  1600 error value =  2.7729431814352976\n",
      "step =  2000 error value =  2.772688240335286\n",
      "step =  2400 error value =  2.7726163038961156\n",
      "step =  2800 error value =  2.7725959593250864\n",
      "step =  3200 error value =  2.7725901991910984\n",
      "step =  3600 error value =  2.7725885674514767\n",
      "step =  4000 error value =  2.7725881050899868\n",
      "step =  4400 error value =  2.772587974061324\n",
      "step =  4800 error value =  2.7725879369269\n",
      "step =  5200 error value =  2.7725879264024518\n",
      "step =  5600 error value =  2.772587923419626\n",
      "step =  6000 error value =  2.7725879225742323\n",
      "step =  6400 error value =  2.7725879223346293\n",
      "step =  6800 error value =  2.7725879222667205\n",
      "step =  7200 error value =  2.772587922247474\n",
      "step =  7600 error value =  2.7725879222420193\n",
      "step =  8000 error value =  2.772587922240473\n",
      "step =  8400 error value =  2.772587922240035\n",
      "step =  8800 error value =  2.7725879222399112\n",
      "step =  9200 error value =  2.7725879222398753\n",
      "step =  9600 error value =  2.772587922239866\n",
      "step =  10000 error value =  2.7725879222398624\n"
     ]
    }
   ],
   "source": [
    "#usage (data feedingm, XOR Gate 검증)\n",
    "\n",
    "xdata = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "tdata = np.array([0, 1, 1, 0])\n",
    "\n",
    "XOR_obj = LogicGate(\"XOR_GATE\", xdata, tdata)\n",
    "\n",
    "XOR_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR_GATE \n",
      "\n",
      "[0 0]  =  0 \n",
      "\n",
      "[0 1]  =  0 \n",
      "\n",
      "[1 0]  =  0 \n",
      "\n",
      "[1 1]  =  1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(XOR_obj.name, \"\\n\")\n",
    "\n",
    "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = XOR_obj.predict(input_data)\n",
    "    print(input_data, \" = \", logical_val, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  =  0\n",
      "\n",
      "[0 1]  =  1\n",
      "\n",
      "[1 0]  =  1\n",
      "\n",
      "[1 1]  =  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XOR 을 NAND + OR => AND 조합으로 계산함\n",
    "input_data = np.array([[0 ,0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "s1 = []\n",
    "s2 = []\n",
    "\n",
    "new_input_data = []\n",
    "final_output = []\n",
    "\n",
    "for index in range(len(input_data)):\n",
    "    \n",
    "    s1 = OR_obj.predict(input_data[index])\n",
    "    s2 = NAND_obj.predict(input_data[index])\n",
    "    \n",
    "    new_input_data.append(s1[-1])\n",
    "    new_input_data.append(s2[-1])\n",
    "    \n",
    "    (sigmoid_val, logical_val) = AND_obj.predict(np.array(new_input_data))\n",
    "    \n",
    "    final_output.append(logical_val)\n",
    "    new_input_data = []\n",
    "    \n",
    "for index in range(len(input_data)):\n",
    "    print(input_data[index], \" = \", final_output[index], end = '')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
